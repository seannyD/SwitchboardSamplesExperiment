print("ORTH A")
print(dx$orthA)
print(dx$id)
}
matchTran = function(samplesExtraData, tran,id, useA = F){
x = samplesExtraData$transcription==tran
y = sw$id==id
if(useA){
samplesExtraData[x,]$sex = sw[y,]$sexA
samplesExtraData[x,]$timeInFile = sw[y,]$time
samplesExtraData[x,]$speakerID = sw[y,]$spkA
samplesExtraData[x,]$swTranscription = sw[y,]$orthA
} else{
samplesExtraData[x,]$sex = sw[y,]$sexB
samplesExtraData[x,]$timeInFile = sw[y,]$time
samplesExtraData[x,]$speakerID = sw[y,]$spkB
samplesExtraData[x,]$swTranscription = sw[y,]$orthB
}
return(samplesExtraData)
}
# Link data to switchboard
allLab = read.csv("../Data/Lab_Processed.csv")
######
# Get data from switchboard
samples = read.csv("../Data/Stimuli_list.csv", stringsAsFactors = F)
sw = read.csv("~/Documents/MPI/Switchboard/NewTorreiraLubbersData/fto_utt_withSynDepthPLUSandPhones6.csv", stringsAsFactors = F)
mx = charmatch(tolower(samples$transcription),sw$orthB)
samplesExtraData = data.frame()
for(file in unique(samples$file)){
swx = sw[sw$file==file,]
sampx = samples[samples$file==file,]
#distNorm = normLev.fnc(c(swx$orthA,swx$orthB),tolower(sampx$transcription))
#distx = adist(swx$orthB,tolower(sampx$transcription))
# distx = normLev.fnc(swx$orthB,tolower(sampx$transcription))
#distx2 = stringdistmatrix(swx$orthB,tolower(sampx$transcription),method='lcs')
#distx2 = distx2/ max(distx2)
distx = adist(swx$orthB,tolower(sampx$transcription), costs=c(ins=1, del=0.5,sub=1))
distxA = adist(swx$orthA,tolower(sampx$transcription), costs=c(ins=1, del=0.5,sub=1))
matches = apply(distx , 2, function(X){which(X==min(X))})
matches = sapply(matches, function(X){if(length(X)>1){return(X[1])} else{return(X)}})
minB = apply(distx , 2, min)
matchesA = apply(distxA , 2, function(X){which(X==min(X))})
matchesA = sapply(matchesA, function(X){if(length(X)>1){return(X[1])} else{return(X)}})
minA = apply(distxA , 2, min)
for(i in 1:length(matches)){
if(minB[i] <= minA[i]){
sampx$sex[i]  = swx[matches[i],]$sexB
sampx$timeInFile[i] = swx[matches[i],]$time
sampx$speakerID[i] = swx[matches[i],]$spkB
sampx$swTranscription[i] = swx[matches[i],]$orthB
} else{
sampx$sex[i]  = swx[matchesA[i],]$sexA
sampx$timeInFile[i] = swx[matchesA[i],]$time
sampx$speakerID[i] = swx[matchesA[i],]$spkA
sampx$swTranscription[i] = swx[matchesA[i],]$orthA
}
}
samplesExtraData = rbind(samplesExtraData, sampx)
}
samplesExtraData$er = abs(nchar(samplesExtraData$transcription) - nchar(samplesExtraData$swTranscription))
t(samplesExtraData[samplesExtraData$er>10 & samplesExtraData$er<=20 & !is.na(samplesExtraData$er),c("transcription","swTranscription",'file')])
####
# Manual fixes
#"well so many of them now eem"
findTran("so many","3223")
samplesExtraData = matchTran(samplesExtraData,"well so many of them now eem",33287)
findTran("liked to","3254")
samplesExtraData = matchTran(samplesExtraData,"well i think our i i never have liked to cook food",'34392')
findTran("while ago","3377")
samplesExtraData = matchTran(samplesExtraData,"quite a while ago it's probbaly up to 20 now if I",'37824', T)
samplesExtraData = matchTran(samplesExtraData,"there certainly been ideas surfaced uh recently um","37926")
findTran("bucks","3311")
samplesExtraData = matchTran(samplesExtraData,'right now i am getting around sixty bucks a month','35877')
findTran('ever been', "3254")
samplesExtraData = matchTran(samplesExtraData,"you ever been to Houston on Beltline",34378,T)
findTran("hobbies","3182" )
samplesExtraData = matchTran(samplesExtraData,"do you have any hobbies",32470, T)
findTran('revenue',"3387")
samplesExtraData = matchTran(samplesExtraData,"is it your expectation that that would raise the total revenues collected or or lower them or what","37995",T)
findTran("course",'3377')
samplesExtraData = matchTran(samplesExtraData,"do you have long waits uh to get on the course",37846)
findTran("Porsche",'3550')
findTran("Buick",'4339')
samplesExtraData = matchTran(samplesExtraData,"we have a Buick Century now",50844,T)
findTran("just",'3345')
samplesExtraData = matchTran(samplesExtraData,"just the events that happen arounf the world interest me",37000,T)
findTran("feel",'4812')
samplesExtraData = matchTran(samplesExtraData,"so how do you feel about it",54018,useA=T)
samplesExtraData = matchTran(samplesExtraData,"well you always",37063)
samplesExtraData = matchTran(samplesExtraData,"but that's the way it goes",36986,T)
samplesExtraData = matchTran(samplesExtraData,"they don't really do that",54077)
samplesExtraData = matchTran(samplesExtraData,"it was flat",41189)
findTran("what do","4104")
samplesExtraData = matchTran(samplesExtraData,"what do i do um",48145)
#findTran("expensive","3232")
#"um the Christian college was so much more expensive"
samplesExtraData$responseType = "none"
samplesExtraData$responseType[samplesExtraData$type %in% c("Non-Q1","Q1")] = "wh"
samplesExtraData$responseType[samplesExtraData$type %in% c("Non-Q2","Q2")] = "other"
samplesExtraData$responseSample = paste(samplesExtraData$responseType, samplesExtraData$Stimuli.ID)
samplesExtraData$responseSample[samplesExtraData$responseType == "none"] = "none"
samplesExtraData$contextSample = NA
samplesExtraData$contextSample[samplesExtraData$type=="Initial"] = "IN"
samplesExtraData$contextSample[samplesExtraData$type=="Statement"] = "ST"
samplesExtraData$contextSample[samplesExtraData$type=="Statement"] = "ST"
samplesExtraData$contextSample = paste(samplesExtraData$contextSample,samplesExtraData$Stimuli.ID)
write.csv(samplesExtraData, "../Data/SamplesExtraData.csv", row.names = F)
allLab$context.sex = samplesExtraData[match(allLab$contextSample,samplesExtraData$contextSample),]$sex
allLab$response.sex = samplesExtraData[match(allLab$responseSample,samplesExtraData$responseSample),]$sex
trx = gsub("\\[[^]]+\\]","",samplesExtraData$transcription)
trx = gsub(" ",'',trx)
samplesExtraData$response.firstO = substr(trx,0,1)
allLab$response.firstO= samplesExtraData[match(allLab$responseSample,samplesExtraData$responseSample),]$response.firstO
write.csv(allLab,"../Data/Lab_Processed.csv")
---
title: "A case for systematic sound symbolism in pragmatics: Supporting information"
output:
pdf_document:
includes:
in_header: header.tex
toc: true
---
```{r echo=F}
getMEText = function(r,ef, wald=NULL){
AIC = r[2,]$AIC
loglikDiff = signif(diff(r$logLik),2)
chi = round(r$Chisq[2],2)
df = r$`Chi Df`[2]
p = signif(r$`Pr(>Chisq)`[2],2)
wald.text = ""
if(!is.null(wald)){
est = signif(wald[1],2)
stder = signif(wald[2],2)
t = signif(wald[3],2)
wptext = ""
if(!is.na(wald[4])){
wptext = paste(", Wald p =",signif(wald[4],2))
}
wald.text = paste("beta = ",est,", std.err = ",stder, ", Wald t = ",t,wptext,';')
}
begin = 'There was no significant'
if(p <0.1){
begin = "There was a marginal"
}
if(p < 0.05){
begin = 'There was a significant'
}
return(paste(begin,ef,"(",wald.text,"log likelihood difference =",
loglikDiff,", df = ",df,", Chi Squared =", chi,", p = ",p,")."))
}
```
# Introduction
This is an analysis of an experiment into whether people can predict if an upcoming turn is a question or a statement, based on the previous turn type and the first phoneme of the target turn.
Participants listened to a series of audio samples.  Each audio sample was made up of a *context* by speaker 1 (Statement or Inititating turn) and a *response* by speaker 2.  The response was either no audio, a single segment [w] or a single semgent other than [w].
# Load libraries
```{r warning=FALSE, message=FALSE}
library(lme4)
library(lattice)
library(gplots)
library(ggplot2)
library(sjPlot)
library(party)
library(Rmisc)
library(dplyr)
```
Function for converting from logit scale
```{r}
logit2per = function(X){
return(exp(X)/(1+exp(X)))
}
```
```{r echo=FALSE}
# Set working directory
setwd("~/Documents/MPI/SemanticsPragmatics/2015Course/Projects/Slonimska/InitialPhonemeExperiment/SwitchboardSamplesExperiment/processing/")
```
# Load data
```{r}
d = read.csv("../Data/Lab_Processed.csv")
```
Each row in the data is a single response from a participant to a single sample.  The key variables are:
-  *partID*:  identifies participants
-  *contextSample*: The name of the audio sample used for the context.
-  *responseSample*: The name of the audio sample used for the response.
-  *responsePhoneme*: The first segment of the response.
-  *responseType*: Whether the first segment of the response came from a question or statement.
-  *answer*: The participant's response to "Is the next turn a question?"
Make *answer* a binary variable.
```{r}
d$answer = d$answer=="Yes"
```
Relevel response phoneme and context.
```{r}
d$responsePhoneme = relevel(d$responsePhoneme, 'other')
d$context = relevel(d$context, 'ST')
```
## Data exclusion
We exclude participant 13 because they took much longer than other participants.
```{r}
d = d[as.character(d$partID)!="13",]
```
Are there any samples that look like outliers?  Make a basic model:
```{r}
m3 = glmer(
answer ~ 1 + context * responsePhoneme +
(1 + context | partID) +
(1 | contextSample) +   # context sample
(1 | responseSample),   # response sample
data = d,
family = binomial
)
```
Then look at the random effects.
```{r}
dotplot(ranef(m3))[[2]]
```
The sample "IN 18" is an outlier.  The turn which makes up this context sample an initiating turn, but this is very difficult to tell whithout the prior context of the conversation.  It looks like people are treating it as a non-initiating turn, so we remove responses where "IN 18" are included:
```{r}
d = d[d$contextSample != 'IN 18',]
```
The data has `r nrow(d)` observations:
```{r}
# Number of observations per participant
table(d$partID)
table(d$context, d$responsePhoneme )
```
\newpage
# Effects of block and trial
```{r}
plotmeans(answer ~ cut(trialNumber,seq(0,50,length.out = 11), include.lowest = T),
ylab = "Prob of answering 'Question'",
xlab = 'Trial',
data = d[d$context=="ST",],ylim=c(0,1),
col = 1, barcol = 1)
plotmeans(answer ~ cut(trialNumber,seq(0,50,length.out = 11), include.lowest = T),
ylab = "Prob of answering 'Question'",
xlab = 'Trial',
data = d[d$context=="IN",],ylim=c(0,1),
col = 2, barcol = 2, add=T)
plotmeans(d$answer ~ d$blockName,
ylab = "Prob of answering 'Question'",
xlab = 'Stimulus set')
plotmeans(d$answer ~ d$lastAnswer)
plotmeans(d$answer ~ d$lastAnswer,
ylab = "Prob of answering 'Question'",
xlab = "Last response")
table(d$answer,d$lastAnswer)
d$lastAnswer = d$lastAnswer=="Yes"
table(d$answer,d$lastAnswer)
plotmeans(d$answer ~ d$lastAnswer,
ylab = "Prob of answering 'Question'",
xlab = "Last response")
plotmeans(d$answer ~ d$lastAnswer,
ylab = "Prob of answering 'Question'",
xlab = "Last response",
legends = c("Not Q", "Question"))
chisq.test(table(d$answer,d$lastAnswer))
plotmeans(answer ~ lastAnswer,
ylab = "Prob of answering 'Question'",
xlab = "Previous response",
legends = c("Not Q", "Question"),
data = d[d$trialNumber!=1,])
cx = ctree(answer ~
trialNumber + lastAnswer,
data = d,
controls = ctree_control(mincriterion = 0.95))
plot(cx)
cx = ctree(answer ~
trialNumber + lastAnswer,
data = d,
controls = ctree_control(mincriterion = 0.5))
plot(cx)
plot(cx, terminal_panel=node_barplot)
cx = ctree(answer ~
context +responsePhoneme + responseType +
Age + Sex + EnglishType +
response.sex + context.sex +
response.firstO + trialNumber + lastAnswer +
blockName,
data = d,
controls = ctree_control(mincriterion = 0.95))
plot(cx, terminal_panel=node_barplot)
m3 = glmer(
answer ~ 1 + context * responsePhoneme +
(1 + context + responsePhoneme | partID) +         # participant
(1 | contextSample) +
(1 | responseSample),    # context sample
data = d,
family = binomial,
control = gcontrol
)
summary(m3)
m3b = glmer(
answer ~ 1 + context * responsePhoneme +
(1 + context + responsePhoneme | partID) +         # participant
(1 | contextSample) +
(1 | responseSample),    # context sample
data = d[d$trialNumber>1,],
family = binomial,
control = gcontrol
)
summary(m3b)
anova(m2,m3)
anova(m2,m3b)
m2b = glmer(
answer ~ 1 + context + responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample),   # context sample
data = d[d$trialNumber>1,],
family = binomial,
control = gcontrol
)
anova(m2b,m3b)
anova(m2,m3)
m3b = glmer(
answer ~ 1 + context * responsePhoneme +
(1 + context + responsePhoneme | partID) +         # participant
(1 | contextSample) +
(1 | responseSample),    # context sample
data = d[d$trialNumber>4,],
family = binomial,
control = gcontrol
)
m2b = glmer(
answer ~ 1 + context + responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample),   # context sample
data = d[d$trialNumber>4,],
family = binomial,
control = gcontrol
)
anova(m2b,m3b)
m3b = glmer(
answer ~ 1 + context * responsePhoneme +
(1 + context + responsePhoneme | partID) +         # participant
(1 | contextSample) +
(1 | responseSample),    # context sample
data = d[d$trialNumber>6,],
family = binomial,
control = gcontrol
)
m2b = glmer(
answer ~ 1 + context + responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample),   # context sample
data = d[d$trialNumber>6,],
family = binomial,
control = gcontrol
)
anova(m2b,m3b)
m2b = glmer(
answer ~ 1 + context + responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) + (1| responseSample),   # context sample
data = d[d$trialNumber>6,],
family = binomial,
control = gcontrol
)
anova(m2b,m3b)
m0 = glmer(
answer ~ 1 +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d,
family = binomial,
control = gcontrol
)
trial = glmer(
answer ~ 1 + trialNumber +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d,
family = binomial,
control = gcontrol
)
prevAns = glmer(
answer ~ 1 + trialNumber + lastAnswer +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d,
family = binomial,
control = gcontrol
)
context = glmer(
answer ~ 1 + trialNumber + lastAnswer +
context +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d,
family = binomial,
control = gcontrol
)
rPhon = glmer(
answer ~ 1 + trialNumber + lastAnswer +
context + responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d,
family = binomial,
control = gcontrol
)
conXrPh = glmer(
answer ~ 1 + trialNumber + lastAnswer +
context * responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d,
family = binomial,
control = gcontrol
)
anova(m0, prevAns, context,rPhon, conXrPh)
anova(m0, trial, prevAns, context,rPhon, conXrPh)
conXrPh = glmer(
answer ~ 1 + trialNumber + lastAnswer +
context * responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d[d$trialNumber > 1],
family = binomial,
control = gcontrol
)
d$trial
conXrPh = glmer(
answer ~ 1 + trialNumber + lastAnswer +
context * responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d[d$trialNumber > 1,],
family = binomial,
control = gcontrol
)
anova(m0, trial, prevAns, context,rPhon, conXrPh)
summary(conXrPh)
d$responsePhoneme = relevel(d$responsePhoneme,'none')
sumStats = group_by(d[d$trialNumber>1,], partID ,context,responsePhoneme ) %>%
summarise(mean = mean(answer))
sumStats2 = summarySE(sumStats, measurevar="mean", groupvars=c("context","responsePhoneme"))
sumStats2$upper = sumStats2$mean + sumStats2$ci
sumStats2$lower = sumStats2$mean - sumStats2$ci
dodge <- position_dodge(width=0.5)
main.plot <- ggplot(sumStats2,
aes(x = responsePhoneme, y = mean, colour=context)) +
geom_point() + geom_line(aes(group=context)) +
geom_errorbar(aes(ymax=mean+ci, ymin=mean-ci), width=0.25) +
xlab("First Phoneme in Response") +
ylab("Proportion of 'Question' responses") +
coord_cartesian(ylim=c(0,1)) +
scale_color_discrete(breaks=c("ST","IN"),
labels=c("Statement","Initiating"),
name="Context")
main.plot
main.plot2 <- ggplot(sumStats2,
aes(x = context, y = mean, colour=responsePhoneme)) +
geom_point(position=dodge) + geom_line(aes(group=responsePhoneme), position=dodge) +
geom_errorbar(aes(ymax=mean+ci, ymin=mean-ci), width=0.25, position=dodge) +
xlab("Previous turn type (context)") +
ylab("Proportion of 'Question' responses") +
coord_cartesian(ylim=c(0,1)) +
scale_color_discrete(breaks=c("none","other",'wh'),
labels=c("None","Non-wh","wh"),
name="First phoneme") +
scale_x_discrete(breaks=c("ST", "IN"),
labels=c("Statement", "Initiating"))
main.plot2
sumStats = group_by(d[d$trialNumber>6,], partID ,context,responsePhoneme ) %>%
summarise(mean = mean(answer))
sumStats2 = summarySE(sumStats, measurevar="mean", groupvars=c("context","responsePhoneme"))
sumStats2$upper = sumStats2$mean + sumStats2$ci
sumStats2$lower = sumStats2$mean - sumStats2$ci
dodge <- position_dodge(width=0.5)
main.plot <- ggplot(sumStats2,
aes(x = responsePhoneme, y = mean, colour=context)) +
geom_point() + geom_line(aes(group=context)) +
geom_errorbar(aes(ymax=mean+ci, ymin=mean-ci), width=0.25) +
xlab("First Phoneme in Response") +
ylab("Proportion of 'Question' responses") +
coord_cartesian(ylim=c(0,1)) +
scale_color_discrete(breaks=c("ST","IN"),
labels=c("Statement","Initiating"),
name="Context")
main.plot
main.plot2 <- ggplot(sumStats2,
aes(x = context, y = mean, colour=responsePhoneme)) +
geom_point(position=dodge) + geom_line(aes(group=responsePhoneme), position=dodge) +
geom_errorbar(aes(ymax=mean+ci, ymin=mean-ci), width=0.25, position=dodge) +
xlab("Previous turn type (context)") +
ylab("Proportion of 'Question' responses") +
coord_cartesian(ylim=c(0,1)) +
scale_color_discrete(breaks=c("none","other",'wh'),
labels=c("None","Non-wh","wh"),
name="First phoneme") +
scale_x_discrete(breaks=c("ST", "IN"),
labels=c("Statement", "Initiating"))
main.plot2
conXrPh = glmer(
answer ~ 1 + trialNumber + lastAnswer +
context * responsePhoneme +
(1 + context + responsePhoneme| partID) +
(1 | contextSample) +
(1 | responseSample),   # context sample
data = d[d$trialNumber > 6,],
family = binomial,
control = gcontrol
)
summary(conXrPh)
